{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "JtUOqs8R-TMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "iMsYyrWE-Tsn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp3ETDEeFVbF",
        "outputId": "7ce1e553-636d-4128-ebd7-cc9ef2102dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Schema:\n",
            "root\n",
            " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
            " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
            " |-- passenger_count: integer (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            "\n",
            "Sample Data:\n",
            "+--------------------+---------------------+---------------+-------------+-----------+\n",
            "|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|fare_amount|\n",
            "+--------------------+---------------------+---------------+-------------+-----------+\n",
            "| 2022-01-03 16:33:41|  2022-01-03 17:25:41|              4|         0.88|       3.32|\n",
            "| 2022-01-08 09:01:55|  2022-01-08 09:35:55|              3|         0.84|       3.02|\n",
            "| 2022-01-15 11:49:25|  2022-01-15 12:06:25|              2|         2.46|       6.58|\n",
            "| 2022-01-20 09:41:33|  2022-01-20 10:00:33|              2|         0.01|       3.27|\n",
            "| 2022-01-09 06:02:02|  2022-01-09 06:35:02|              5|         2.95|       10.9|\n",
            "+--------------------+---------------------+---------------+-------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------------+\n",
            "|avg_fare_per_mile|\n",
            "+-----------------+\n",
            "| 8.35430205867382|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "#Initialize spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "        .appName(\"NYC Taxi Trip Analysis\") \\\n",
        "        .getOrCreate()\n",
        " #load the data\n",
        "file_path =\"/content/sample_taxi_nyc.csv - Sheet1.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "print(\"Schema:\")\n",
        "df.printSchema()\n",
        "print(\"Sample Data:\")\n",
        "#preview data\n",
        "df.show(5)\n",
        "# data cleaning\n",
        "from pyspark.sql.functions import col\n",
        "# filter out trip with negative or invalid values\n",
        "df_clean = df.filter(\n",
        "    (col(\"trip_distance\")>0) &\n",
        "    (col(\"fare_amount\")>0) &\n",
        "    (col(\"passenger_count\")>0)\n",
        ")\n",
        "# feature engineering\n",
        "from pyspark.sql.functions import hour, to_timestamp\n",
        "df_features = df_clean.withColumn(\"pickup_hour\", hour(to_timestamp(col(\"tpep_pickup_datetime\"))))\n",
        "# aggregation - total trips with hour\n",
        "trips_by_hour = df_features.groupBy(\"pickup_hour\").count().orderBy(\"pickup_hour\")\n",
        "#aggregation - average of fare per file\n",
        "from pyspark.sql.functions import avg\n",
        "fare_per_mile = df_features.withColumn(\"fare_per_mile\",col(\"fare_amount\")/col(\"trip_distance\"))\n",
        "avg_fare = fare_per_mile.select(avg(\"fare_per_mile\").alias(\"avg_fare_per_mile\"))\n",
        "avg_fare.show()\n",
        "# top 10 longest trip\n",
        "longest_trips = df_features.orderBy(col(\"trip_distance\").desc()).select(\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"trip_distance\",\"fare_amount\").limit(10)\n",
        "# save if needed\n",
        "# longest_trip.write.csv(\"output/longest_trips.csv\",header = true)\n",
        "# stop spark session\n",
        "spark.stop()"
      ]
    }
  ]
}